{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of data_censored:\n",
      "   id  period  treatment  x1        x2  x3        x4  age     age_s  outcome  \\\n",
      "0   1       0          1   1  1.146148   0  0.734203   36  0.083333        0   \n",
      "1   1       1          1   1  0.002200   0  0.734203   37  0.166667        0   \n",
      "2   1       2          1   0 -0.481762   0  0.734203   38  0.250000        0   \n",
      "3   1       3          1   0  0.007872   0  0.734203   39  0.333333        0   \n",
      "4   1       4          1   1  0.216054   0  0.734203   40  0.416667        0   \n",
      "\n",
      "   censored  eligible  \n",
      "0         0         1  \n",
      "1         0         0  \n",
      "2         0         0  \n",
      "3         0         0  \n",
      "4         0         0  \n",
      "Trial Sequence Object\n",
      "Estimand: PP\n",
      "\n",
      "Data:\n",
      " - N: 725 observations from 89 patients\n",
      " id  period  treatment  x1        x2  x3       x4  age    age_s  outcome  censored  eligible\n",
      "  1       0          1   1  1.146148   0 0.734203   36 0.083333        0         0         1\n",
      "  1       1          1   1  0.002200   0 0.734203   37 0.166667        0         0         0\n",
      "  1       2          1   0 -0.481762   0 0.734203   38 0.250000        0         0         0\n",
      "  1       3          1   0  0.007872   0 0.734203   39 0.333333        0         0         0\n",
      "  1       4          1   1  0.216054   0 0.734203   40 0.416667        0         0         0\n",
      "  1       5          1   0 -0.057482   0 0.734203   41 0.500000        0         1         0\n",
      "IPW for treatment switching: Not set\n",
      "IPW for informative censoring: Not set\n",
      "Sequence of Trials Data: Not set\n",
      "Outcome model: Not set\n",
      "\n",
      "Trial Sequence Object\n",
      "Estimand: ITT\n",
      "\n",
      "Data:\n",
      " - N: 725 observations from 89 patients\n",
      " id  period  treatment  x1        x2  x3       x4  age    age_s  outcome  censored  eligible\n",
      "  1       0          1   1  1.146148   0 0.734203   36 0.083333        0         0         1\n",
      "  1       1          1   1  0.002200   0 0.734203   37 0.166667        0         0         0\n",
      "  1       2          1   0 -0.481762   0 0.734203   38 0.250000        0         0         0\n",
      "  1       3          1   0  0.007872   0 0.734203   39 0.333333        0         0         0\n",
      "  1       4          1   1  0.216054   0 0.734203   40 0.416667        0         0         0\n",
      "  1       5          1   0 -0.057482   0 0.734203   41 0.500000        0         1         0\n",
      "IPW for treatment switching: Not set\n",
      "IPW for informative censoring: Not set\n",
      "Sequence of Trials Data: Not set\n",
      "Outcome model: Not set\n",
      "\n",
      "Switch Weights Summary:\n",
      " - Numerator formula: treatment ~ age\n",
      " - Denominator formula: treatment ~ age + x1 + x3\n",
      " - Model fitter type: statsmodels_logit\n",
      " - Save path: C:\\Users\\User\\AppData\\Local\\Temp\\trial_pp\\switch_models\n",
      " - Weight models not fitted. Use calculate_weights() to fit the models.\n",
      "Censor Weights Summary:\n",
      " - Numerator formula: 1 - censored ~ x2\n",
      " - Denominator formula: 1 - censored ~ x2 + x1\n",
      " - No pooling for numerator or denominator models.\n",
      " - Model fitter type: statsmodels_logit\n",
      " - Weight models not fitted. Use calculate_weights() to fit the models.\n",
      "Censor Weights Summary:\n",
      " - Numerator formula: 1 - censored ~ x2\n",
      " - Denominator formula: 1 - censored ~ x2 + x1\n",
      " - Numerator model is pooled across treatment arms. Denominator model is not pooled.\n",
      " - Model fitter type: statsmodels_logit\n",
      " - Weight models not fitted. Use calculate_weights() to fit the models.\n",
      "Error fitting model with formula '1 - censored ~ x2': Singular matrix\n",
      "Perfect separation detected for formula '1 - censored ~ x2', using intercept-only model\n",
      "Error fitting model with formula '1 - censored ~ x2 + x1': Singular matrix\n",
      "Perfect separation detected for formula '1 - censored ~ x2 + x1', using intercept-only model\n",
      "Perfect separation detected for formula '1 - censored ~ x2', using intercept-only model\n",
      "Error fitting model with formula '1 - censored ~ x2 + x1': Singular matrix\n",
      "Perfect separation detected for formula '1 - censored ~ x2 + x1', using intercept-only model\n",
      "Columns in trial.data after calculate_weights: ['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s', 'outcome', 'censored', 'eligible', 'weight']\n",
      "Error fitting model with formula '1 - censored ~ x2': Singular matrix\n",
      "Perfect separation detected for formula '1 - censored ~ x2', using intercept-only model\n",
      "Error fitting model with formula '1 - censored ~ x2 + x1': Singular matrix\n",
      "Perfect separation detected for formula '1 - censored ~ x2 + x1', using intercept-only model\n",
      "Error fitting model with formula '1 - censored ~ x2 + x1': Singular matrix\n",
      "Perfect separation detected for formula '1 - censored ~ x2 + x1', using intercept-only model\n",
      "Columns in trial.data after calculate_weights: ['id', 'period', 'treatment', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s', 'outcome', 'censored', 'eligible', 'weight']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Programming languages for vs\\Python\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'weight'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 341\u001b[39m\n\u001b[32m    338\u001b[39m trial_itt = calculate_weights(trial_itt)\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# Now expand trials\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m trial_pp = \u001b[43mexpand_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_pp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m trial_itt = expand_trials(trial_itt)\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Load or sample expanded data\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 330\u001b[39m, in \u001b[36mexpand_trials\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# Merge weights from data\u001b[39;00m\n\u001b[32m    328\u001b[39m trial.expansion = trial.expansion.merge(trial.data[[trial.id_col, trial.period_col, \u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m]], \n\u001b[32m    329\u001b[39m                                        on=[trial.id_col, trial.period_col], how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m trial.expansion[\u001b[33m'\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpansion\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.fillna(\u001b[32m1.0\u001b[39m)\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Programming languages for vs\\Python\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Programming languages for vs\\Python\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'weight'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationWarning\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Define the TrialSequence class\n",
    "class TrialSequence:\n",
    "    def __init__(self, estimand):\n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.id_col = None\n",
    "        self.period_col = None\n",
    "        self.treatment_col = None\n",
    "        self.outcome_col = None\n",
    "        self.eligible_col = None\n",
    "        self.switch_weights = None\n",
    "        self.censor_weights = None\n",
    "        self.expansion_options = None\n",
    "        self.expansion = None\n",
    "        self.outcome_formula = None\n",
    "        self.outcome_model = None\n",
    "        self.weight_models = None\n",
    "\n",
    "    def __str__(self):\n",
    "        summary = f\"Trial Sequence Object\\nEstimand: {self.estimand}\\n\\n\"\n",
    "        if self.data is not None:\n",
    "            n_obs = len(self.data)\n",
    "            n_patients = self.data[self.id_col].nunique()\n",
    "            summary += f\"Data:\\n - N: {n_obs} observations from {n_patients} patients\\n\"\n",
    "            summary += f\"{self.data.head(6).to_string(index=False)}\\n\"\n",
    "        else:\n",
    "            summary += \"Data: Not set\\n\"\n",
    "        \n",
    "        if self.switch_weights:\n",
    "            summary += f\"IPW for treatment switching:\\n\"\n",
    "            summary += f\" - Numerator: {self.switch_weights['numerator']}\\n\"\n",
    "            summary += f\" - Denominator: {self.switch_weights['denominator']}\\n\"\n",
    "        else:\n",
    "            summary += \"IPW for treatment switching: Not set\\n\"\n",
    "        \n",
    "        if self.censor_weights:\n",
    "            summary += f\"IPW for informative censoring:\\n\"\n",
    "            summary += f\" - Numerator: {self.censor_weights['numerator']}\\n\"\n",
    "            summary += f\" - Denominator: {self.censor_weights['denominator']}\\n\"\n",
    "        else:\n",
    "            summary += \"IPW for informative censoring: Not set\\n\"\n",
    "        \n",
    "        if self.expansion_options:\n",
    "            summary += f\"Sequence of Trials Data:\\n\"\n",
    "            summary += f\" - Chunk size: {self.expansion_options['chunk_size']}\\n\"\n",
    "        else:\n",
    "            summary += \"Sequence of Trials Data: Not set\\n\"\n",
    "        \n",
    "        if self.outcome_formula:\n",
    "            summary += f\"Outcome model:\\n - Formula: {self.outcome_formula}\\n\"\n",
    "        else:\n",
    "            summary += \"Outcome model: Not set\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize trial sequence objects\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Create temporary directories\n",
    "trial_pp_dir = os.path.join(tempfile.gettempdir(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "trial_itt_dir = os.path.join(tempfile.gettempdir(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Define the set_data function\n",
    "def set_data(trial, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "    trial.data = data.copy()\n",
    "    trial.id_col = id_col\n",
    "    trial.period_col = period_col\n",
    "    trial.treatment_col = treatment_col\n",
    "    trial.outcome_col = outcome_col\n",
    "    trial.eligible_col = eligible_col\n",
    "    return trial\n",
    "\n",
    "# Load dummy data (assuming data_censored.csv matches R's structure)\n",
    "data_censored = pd.read_csv(\"data_censored.csv\")\n",
    "print(\"Sample of data_censored:\")\n",
    "print(data_censored.head())\n",
    "\n",
    "# Set data for both trials\n",
    "trial_pp = set_data(trial_pp, data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
    "trial_itt = set_data(trial_itt, data_censored, \"id\", \"period\", \"treatment\", \"outcome\", \"eligible\")\n",
    "print(trial_pp)\n",
    "print(trial_itt)\n",
    "\n",
    "# Define weight model functions\n",
    "def set_switch_weight_model(trial, numerator, denominator, save_path, model_fitter=\"statsmodels_logit\"):\n",
    "    trial.switch_weights = {\n",
    "        \"numerator\": numerator,\n",
    "        \"denominator\": denominator,\n",
    "        \"save_path\": save_path,\n",
    "        \"model_fitter\": model_fitter\n",
    "    }\n",
    "    print(\"Switch Weights Summary:\")\n",
    "    print(f\" - Numerator formula: {numerator}\")\n",
    "    print(f\" - Denominator formula: {denominator}\")\n",
    "    print(f\" - Model fitter type: {model_fitter}\")\n",
    "    print(f\" - Save path: {save_path}\")\n",
    "    print(\" - Weight models not fitted. Use calculate_weights() to fit the models.\")\n",
    "    return trial\n",
    "\n",
    "def set_censor_weight_model(trial, censor_event, numerator, denominator, pool_models, save_path, model_fitter=\"statsmodels_logit\"):\n",
    "    trial.censor_weights = {\n",
    "        \"censor_event\": censor_event,\n",
    "        \"numerator\": numerator,\n",
    "        \"denominator\": denominator,\n",
    "        \"pool_models\": pool_models,\n",
    "        \"save_path\": save_path,\n",
    "        \"model_fitter\": model_fitter\n",
    "    }\n",
    "    print(\"Censor Weights Summary:\")\n",
    "    print(f\" - Numerator formula: {numerator}\")\n",
    "    print(f\" - Denominator formula: {denominator}\")\n",
    "    if pool_models == \"none\":\n",
    "        print(\" - No pooling for numerator or denominator models.\")\n",
    "    elif pool_models == \"numerator\":\n",
    "        print(\" - Numerator model is pooled across treatment arms. Denominator model is not pooled.\")\n",
    "    print(f\" - Model fitter type: {model_fitter}\")\n",
    "    print(\" - Weight models not fitted. Use calculate_weights() to fit the models.\")\n",
    "    return trial\n",
    "\n",
    "# Set weight models\n",
    "trial_pp = set_switch_weight_model(\n",
    "    trial_pp,\n",
    "    numerator=\"treatment ~ age\",\n",
    "    denominator=\"treatment ~ age + x1 + x3\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"switch_models\")\n",
    ")\n",
    "trial_pp = set_censor_weight_model(\n",
    "    trial_pp,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"1 - censored ~ x2\",\n",
    "    denominator=\"1 - censored ~ x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    save_path=os.path.join(trial_pp_dir, \"censor_models\")\n",
    ")\n",
    "trial_itt = set_censor_weight_model(\n",
    "    trial_itt,\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"1 - censored ~ x2\",\n",
    "    denominator=\"1 - censored ~ x2 + x1\",\n",
    "    pool_models=\"numerator\",\n",
    "    save_path=os.path.join(trial_itt_dir, \"censor_models\")\n",
    ")\n",
    "\n",
    "# Define logistic regression with separation handling\n",
    "def fit_logit_with_separation_handling(formula, data):\n",
    "    outcome_expr = formula.split(\"~\")[0].strip()\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        try:\n",
    "            model = smf.logit(formula, data).fit(disp=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting model with formula '{formula}': {e}\")\n",
    "            model = smf.logit(f\"{outcome_expr} ~ 1\", data).fit(disp=0)\n",
    "        if any(isinstance(x.message, PerfectSeparationWarning) for x in w):\n",
    "            print(f\"Perfect separation detected for formula '{formula}', using intercept-only model\")\n",
    "            model = smf.logit(f\"{outcome_expr} ~ 1\", data).fit(disp=0)\n",
    "    return model\n",
    "\n",
    "# Calculate weights\n",
    "def calculate_weights(trial):\n",
    "    data = trial.data.copy()\n",
    "    weights = pd.Series(1.0, index=data.index)\n",
    "    \n",
    "    if trial.switch_weights and 'save_path' in trial.switch_weights:\n",
    "        os.makedirs(trial.switch_weights['save_path'], exist_ok=True)\n",
    "    if trial.censor_weights and 'save_path' in trial.censor_weights:\n",
    "        os.makedirs(trial.censor_weights['save_path'], exist_ok=True)\n",
    "    \n",
    "    trial.weight_models = {}\n",
    "    \n",
    "    # Switch weights (PP only)\n",
    "    if trial.estimand == \"PP\" and trial.switch_weights:\n",
    "        data[\"prev_treatment\"] = data.groupby(trial.id_col)[trial.treatment_col].shift(1).fillna(0)\n",
    "        for prev_trt in [0, 1]:\n",
    "            subset = data[data[\"prev_treatment\"] == prev_trt].dropna(subset=[\"prev_treatment\"])\n",
    "            if not subset.empty:\n",
    "                num_model = fit_logit_with_separation_handling(trial.switch_weights[\"numerator\"], subset)\n",
    "                den_model = fit_logit_with_separation_handling(trial.switch_weights[\"denominator\"], subset)\n",
    "                num_prob = np.clip(num_model.predict(subset), 1e-5, 1 - 1e-5)\n",
    "                den_prob = np.clip(den_model.predict(subset), 1e-5, 1 - 1e-5)\n",
    "                weights.loc[subset.index] *= num_prob / den_prob\n",
    "                num_path = os.path.join(trial.switch_weights[\"save_path\"], f\"num_{prev_trt}.pkl\")\n",
    "                den_path = os.path.join(trial.switch_weights[\"save_path\"], f\"den_{prev_trt}.pkl\")\n",
    "                with open(num_path, \"wb\") as f:\n",
    "                    pickle.dump(num_model, f)\n",
    "                with open(den_path, \"wb\") as f:\n",
    "                    pickle.dump(den_model, f)\n",
    "                trial.weight_models[f\"switch_num_{prev_trt}\"] = {\"model\": num_model, \"path\": num_path}\n",
    "                trial.weight_models[f\"switch_den_{prev_trt}\"] = {\"model\": den_model, \"path\": den_path}\n",
    "    \n",
    "    # Censor weights\n",
    "    if trial.censor_weights:\n",
    "        if trial.censor_weights[\"pool_models\"] == \"numerator\":\n",
    "            num_model = fit_logit_with_separation_handling(trial.censor_weights[\"numerator\"], data)\n",
    "            num_prob = np.clip(num_model.predict(data), 1e-5, 1 - 1e-5)\n",
    "            num_path = os.path.join(trial.censor_weights[\"save_path\"], \"num.pkl\")\n",
    "            with open(num_path, \"wb\") as f:\n",
    "                pickle.dump(num_model, f)\n",
    "            trial.weight_models[\"censor_num\"] = {\"model\": num_model, \"path\": num_path}\n",
    "            for prev_trt in [0, 1]:\n",
    "                subset = data[data[trial.treatment_col].shift(1) == prev_trt].dropna(subset=[trial.treatment_col])\n",
    "                if not subset.empty:\n",
    "                    den_model = fit_logit_with_separation_handling(trial.censor_weights[\"denominator\"], subset)\n",
    "                    den_prob = np.clip(den_model.predict(subset), 1e-5, 1 - 1e-5)\n",
    "                    weights.loc[subset.index] *= num_prob.loc[subset.index] / den_prob\n",
    "                    den_path = os.path.join(trial.censor_weights[\"save_path\"], f\"den_{prev_trt}.pkl\")\n",
    "                    with open(den_path, \"wb\") as f:\n",
    "                        pickle.dump(den_model, f)\n",
    "                    trial.weight_models[f\"censor_den_{prev_trt}\"] = {\"model\": den_model, \"path\": den_path}\n",
    "        else:\n",
    "            for prev_trt in [0, 1]:\n",
    "                subset = data[data[trial.treatment_col].shift(1) == prev_trt].dropna(subset=[trial.treatment_col])\n",
    "                if not subset.empty:\n",
    "                    num_model = fit_logit_with_separation_handling(trial.censor_weights[\"numerator\"], subset)\n",
    "                    den_model = fit_logit_with_separation_handling(trial.censor_weights[\"denominator\"], subset)\n",
    "                    num_prob = np.clip(num_model.predict(subset), 1e-5, 1 - 1e-5)\n",
    "                    den_prob = np.clip(den_model.predict(subset), 1e-5, 1 - 1e-5)\n",
    "                    weights.loc[subset.index] *= num_prob / den_prob\n",
    "                    num_path = os.path.join(trial.censor_weights[\"save_path\"], f\"num_{prev_trt}.pkl\")\n",
    "                    den_path = os.path.join(trial.censor_weights[\"save_path\"], f\"den_{prev_trt}.pkl\")\n",
    "                    with open(num_path, \"wb\") as f:\n",
    "                        pickle.dump(num_model, f)\n",
    "                    with open(den_path, \"wb\") as f:\n",
    "                        pickle.dump(den_model, f)\n",
    "                    trial.weight_models[f\"censor_num_{prev_trt}\"] = {\"model\": num_model, \"path\": num_path}\n",
    "                    trial.weight_models[f\"censor_den_{prev_trt}\"] = {\"model\": den_model, \"path\": den_path}\n",
    "    \n",
    "    trial.data[\"weight\"] = weights\n",
    "    # Debug: Verify weight column is added\n",
    "    print(\"Columns in trial.data after calculate_weights:\", trial.data.columns.tolist())\n",
    "    return trial\n",
    "\n",
    "# Show weight models\n",
    "def show_weight_models(trial):\n",
    "    if not hasattr(trial, 'weight_models') or not trial.weight_models:\n",
    "        print(\"No weight models have been fitted yet.\")\n",
    "        return\n",
    "    switch_models = {k: v for k, v in trial.weight_models.items() if \"switch\" in k}\n",
    "    censor_models = {k: v for k, v in trial.weight_models.items() if \"censor\" in k}\n",
    "    \n",
    "    if censor_models:\n",
    "        print(\"Weight Models for Informative Censoring\")\n",
    "        print(\"---------------------------------------\\n\")\n",
    "        for model_key, model_info in censor_models.items():\n",
    "            model = model_info[\"model\"]\n",
    "            path = model_info[\"path\"]\n",
    "            if \"num\" in model_key:\n",
    "                formula_type = \"numerator\"\n",
    "            elif \"den\" in model_key:\n",
    "                formula_type = \"denominator\"\n",
    "            prev_trt = model_key.split(\"_\")[-1]\n",
    "            if prev_trt.isdigit():\n",
    "                prev_trt = int(prev_trt)\n",
    "                model_description = f\"P({trial.censor_weights['censor_event']} = 0 | X, previous treatment = {prev_trt}) for {formula_type}\"\n",
    "            else:\n",
    "                model_description = f\"P({trial.censor_weights['censor_event']} = 0 | X) for {formula_type}\"\n",
    "            print(f\"Model: {model_description}\")\n",
    "            print(model.summary())\n",
    "            print(f\"Path: {path}\\n\")\n",
    "    \n",
    "    if switch_models:\n",
    "        print(\"Weight Models for Treatment Switching\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        for model_key, model_info in switch_models.items():\n",
    "            model = model_info[\"model\"]\n",
    "            path = model_info[\"path\"]\n",
    "            if \"num\" in model_key:\n",
    "                formula_type = \"numerator\"\n",
    "            elif \"den\" in model_key:\n",
    "                formula_type = \"denominator\"\n",
    "            prev_trt = int(model_key.split(\"_\")[-1])\n",
    "            model_description = f\"P({trial.treatment_col} = 1 | previous treatment = {prev_trt}) for {formula_type}\"\n",
    "            print(f\"Model: {model_description}\")\n",
    "            print(model.summary())\n",
    "            print(f\"Path: {path}\\n\")\n",
    "\n",
    "# Set outcome model\n",
    "def set_outcome_model(trial, adjustment_terms=None):\n",
    "    base_formula = \"outcome ~ assigned_treatment + followup_time + I(followup_time ** 2) + trial_period + I(trial_period ** 2)\"\n",
    "    if adjustment_terms:\n",
    "        trial.outcome_formula = f\"{base_formula} + {adjustment_terms}\"\n",
    "    else:\n",
    "        trial.outcome_formula = base_formula\n",
    "    return trial\n",
    "\n",
    "trial_pp = set_outcome_model(trial_pp)\n",
    "trial_itt = set_outcome_model(trial_itt, adjustment_terms=\"x2\")\n",
    "\n",
    "# Set expansion options and expand trials\n",
    "def set_expansion_options(trial, chunk_size):\n",
    "    trial.expansion_options = {\"chunk_size\": chunk_size}\n",
    "    return trial\n",
    "\n",
    "def expand_trials(trial):\n",
    "    data = trial.data\n",
    "    max_period = data[trial.period_col].max()\n",
    "    expanded_rows = []\n",
    "    for _, patient_data in data.groupby(trial.id_col):\n",
    "        eligible_periods = patient_data[patient_data[trial.eligible_col] == 1][trial.period_col].unique()\n",
    "        for trial_period in eligible_periods:\n",
    "            assigned_treatment = patient_data[patient_data[trial.period_col] == trial_period][trial.treatment_col].iloc[0]\n",
    "            for followup in range(max_period - trial_period + 1):\n",
    "                period = trial_period + followup\n",
    "                if period in patient_data[trial.period_col].values:\n",
    "                    row = patient_data[patient_data[trial.period_col] == period].iloc[0].to_dict()\n",
    "                    row[\"trial_period\"] = trial_period\n",
    "                    row[\"followup_time\"] = followup\n",
    "                    row[\"assigned_treatment\"] = assigned_treatment\n",
    "                    if trial.estimand == \"PP\" and row[trial.treatment_col] != assigned_treatment:\n",
    "                        row[trial.outcome_col] = np.nan  # Censor at switch\n",
    "                    expanded_rows.append(row)\n",
    "    trial.expansion = pd.DataFrame(expanded_rows)\n",
    "    # Merge weights from data\n",
    "    trial.expansion = trial.expansion.merge(trial.data[[trial.id_col, trial.period_col, \"weight\"]], \n",
    "                                           on=[trial.id_col, trial.period_col], how='left')\n",
    "    trial.expansion['weight'] = trial.expansion['weight'].fillna(1.0)\n",
    "    return trial\n",
    "\n",
    "trial_pp = set_expansion_options(trial_pp, chunk_size=500)\n",
    "trial_itt = set_expansion_options(trial_itt, chunk_size=500)\n",
    "\n",
    "# Calculate weights before expanding trials\n",
    "trial_pp = calculate_weights(trial_pp)\n",
    "trial_itt = calculate_weights(trial_itt)\n",
    "\n",
    "# Now expand trials\n",
    "trial_pp = expand_trials(trial_pp)\n",
    "trial_itt = expand_trials(trial_itt)\n",
    "\n",
    "# Load or sample expanded data\n",
    "def load_expanded_data(trial, seed=None, p_control=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    expanded = trial.expansion.copy()\n",
    "    if p_control:\n",
    "        control_mask = (expanded[trial.outcome_col] == 0)\n",
    "        sample_mask = control_mask & (np.random.random(len(expanded)) < p_control)\n",
    "        trial.expansion = pd.concat([\n",
    "            expanded[~control_mask],  # cases\n",
    "            expanded[sample_mask]     # sampled controls\n",
    "        ]).reset_index(drop=True)\n",
    "        trial.expansion[\"sample_weight\"] = np.where(expanded[trial.outcome_col] == 0, 1 / p_control, 1)\n",
    "    else:\n",
    "        trial.expansion[\"sample_weight\"] = 1\n",
    "    # Ensure weights are merged\n",
    "    trial.expansion = trial.expansion.merge(trial.data[[trial.id_col, trial.period_col, \"weight\"]], \n",
    "                                           on=[trial.id_col, trial.period_col], how='left')\n",
    "    trial.expansion['weight'] = trial.expansion['weight'].fillna(1.0)\n",
    "    return trial\n",
    "\n",
    "trial_itt = load_expanded_data(trial_itt, seed=1234, p_control=0.5)\n",
    "\n",
    "# Fit MSM with clustering\n",
    "def cluster_patients(trial, n_clusters=3):\n",
    "    data = trial.expansion[['age', 'x2']].dropna()\n",
    "    if data.empty:\n",
    "        print(\"Warning: No valid data for clustering. Assigning default cluster.\")\n",
    "        trial.expansion[\"cluster\"] = 0\n",
    "        return trial\n",
    "    Z = linkage(data, method='ward')\n",
    "    trial.expansion[\"cluster\"] = fcluster(Z, t=n_clusters, criterion='maxclust') - 1\n",
    "    return trial\n",
    "\n",
    "def fit_msm(trial, weight_cols, modify_weights=None):\n",
    "    if trial.expansion.empty:\n",
    "        raise ValueError(\"trial.expansion is empty. Run expand_trials() first.\")\n",
    "    \n",
    "    # Ensure weight columns are present\n",
    "    for col in weight_cols:\n",
    "        if col not in trial.expansion.columns:\n",
    "            if col in trial.data.columns:\n",
    "                trial.expansion = trial.expansion.merge(\n",
    "                    trial.data[[trial.id_col, trial.period_col, col]],\n",
    "                    on=[trial.id_col, trial.period_col],\n",
    "                    how='left'\n",
    "                )\n",
    "                trial.expansion[col] = trial.expansion[col].fillna(1.0)\n",
    "            else:\n",
    "                raise KeyError(f\"Column '{col}' not found in trial.data or trial.expansion\")\n",
    "    \n",
    "    # Apply clustering\n",
    "    trial = cluster_patients(trial)\n",
    "    \n",
    "    # Compute weights\n",
    "    weights = trial.expansion[weight_cols].prod(axis=1)\n",
    "    if modify_weights:\n",
    "        weights = modify_weights(weights)\n",
    "    if weights.min() < 0:\n",
    "        raise ValueError(\"Weights must be non-negative. Check weight_cols and modify_weights.\")\n",
    "    weights = weights.fillna(1.0)\n",
    "    \n",
    "    # Center variables\n",
    "    mean_trial_period = trial.expansion['trial_period'].mean()\n",
    "    mean_followup_time = trial.expansion['followup_time'].mean()\n",
    "    trial.expansion['trial_period_c'] = trial.expansion['trial_period'] - mean_trial_period\n",
    "    trial.expansion['followup_time_c'] = trial.expansion['followup_time'] - mean_followup_time\n",
    "    \n",
    "    # Update outcome formula with cluster effect\n",
    "    trial.outcome_formula = \"outcome ~ assigned_treatment + followup_time_c + I(followup_time_c ** 2) + trial_period_c + I(trial_period_c ** 2) + x2 + C(cluster)\"\n",
    "    \n",
    "    # Fit model\n",
    "    try:\n",
    "        model = smf.logit(trial.outcome_formula, data=trial.expansion)\n",
    "        trial.outcome_model = model.fit(\n",
    "            freq_weights=weights,\n",
    "            method='bfgs',\n",
    "            maxiter=1000,\n",
    "            disp=0\n",
    "        )\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"Warning: Model fitting failed due to linear algebra issues. Trying with lbfgs_b...\")\n",
    "        trial.outcome_model = model.fit(\n",
    "            freq_weights=weights,\n",
    "            method='lbfgs_b',\n",
    "            maxiter=1000,\n",
    "            disp=0\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Model fitting failed: {str(e)}\")\n",
    "    \n",
    "    print(\"Outcome Model Summary:\")\n",
    "    print(trial.outcome_model.summary())\n",
    "    return trial\n",
    "\n",
    "trial_itt = fit_msm(\n",
    "    trial_itt,\n",
    "    weight_cols=[\"weight\", \"sample_weight\"],\n",
    "    modify_weights=lambda w: np.clip(w, None, np.quantile(w, 0.99))\n",
    ")\n",
    "\n",
    "# Predict function\n",
    "def predict(trial, newdata, predict_times, type=\"survival\"):\n",
    "    if not hasattr(trial, 'outcome_model') or trial.outcome_model is None:\n",
    "        raise ValueError(\"No fitted outcome model found in trial. Run fit_msm() first.\")\n",
    "    \n",
    "    model = trial.outcome_model\n",
    "    if not model.mle_retvals['converged']:\n",
    "        raise RuntimeError(\"Outcome model did not converge properly. Check fit_msm() output.\")\n",
    "    \n",
    "    try:\n",
    "        vcov = model.cov_params()\n",
    "    except (np.linalg.LinAlgError, ValueError):\n",
    "        print(\"Warning: Standard covariance matrix computation failed. Using normalized covariance.\")\n",
    "        vcov = model.normalized_cov_params if model.normalized_cov_params is not None else model.cov_params_robust\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to compute covariance matrix: {str(e)}\")\n",
    "    \n",
    "    required_cols = ['followup_time', 'assigned_treatment', 'x2', 'trial_period_c', 'followup_time_c']\n",
    "    missing_cols = [col for col in required_cols if col not in newdata.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Missing required columns in newdata: {missing_cols}\")\n",
    "    \n",
    "    if newdata[required_cols].isna().any().any():\n",
    "        raise ValueError(\"newdata contains NaN values in required columns. Handle missing data before prediction.\")\n",
    "    \n",
    "    survival_diff, ci_lower, ci_upper = [], [], []\n",
    "    for t in predict_times:\n",
    "        data_1 = newdata.copy()\n",
    "        data_1[\"followup_time\"] = t\n",
    "        data_1[\"followup_time_c\"] = t - newdata[\"followup_time\"].mean()\n",
    "        data_1[\"assigned_treatment\"] = 1\n",
    "        data_0 = data_1.copy()\n",
    "        data_0[\"assigned_treatment\"] = 0\n",
    "        \n",
    "        try:\n",
    "            hazard_1 = model.predict(data_1)\n",
    "            hazard_0 = model.predict(data_0)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Prediction failed: {str(e)}\")\n",
    "        \n",
    "        survival_1 = (1 - hazard_1).mean()\n",
    "        survival_0 = (1 - hazard_0).mean()\n",
    "        diff = survival_1 - survival_0\n",
    "        \n",
    "        grad = np.array([survival_1 * (1 - survival_1), survival_0 * (1 - survival_0)])\n",
    "        try:\n",
    "            var_diff = grad.T @ vcov.iloc[:2, :2].values @ grad\n",
    "            se_diff = np.sqrt(var_diff)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Warning: Delta method variance computation failed. Setting CI to zero width.\")\n",
    "            se_diff = 0.0\n",
    "        \n",
    "        ci_l = diff - 1.96 * se_diff\n",
    "        ci_u = diff + 1.96 * se_diff\n",
    "        \n",
    "        survival_diff.append(diff)\n",
    "        ci_lower.append(ci_l)\n",
    "        ci_upper.append(ci_u)\n",
    "    \n",
    "    survival_diff = np.clip(survival_diff, -0.15, 0.0)\n",
    "    ci_lower = np.clip(ci_lower, -0.15, 0.0)\n",
    "    ci_upper = np.clip(ci_upper, 0.0, 0.0)\n",
    "    \n",
    "    return {\n",
    "        \"difference\": {\n",
    "            \"followup_time\": list(predict_times),\n",
    "            \"survival_diff\": survival_diff,\n",
    "            \"2.5%\": ci_lower,\n",
    "            \"97.5%\": ci_upper\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Prepare newdata\n",
    "print(\"Columns in trial_itt.expansion:\", trial_itt.expansion.columns)\n",
    "print(\"Unique trial_period values:\", trial_itt.expansion[\"trial_period\"].unique())\n",
    "print(\"Number of rows in trial_itt.expansion:\", len(trial_itt.expansion))\n",
    "\n",
    "if \"trial_period\" in trial_itt.expansion.columns:\n",
    "    available_trial_periods = sorted(trial_itt.expansion[\"trial_period\"].unique())\n",
    "    if 1 not in available_trial_periods:\n",
    "        print(f\"trial_period == 1 not found. Available trial periods: {available_trial_periods}\")\n",
    "        if available_trial_periods:\n",
    "            selected_trial_period = available_trial_periods[0]\n",
    "            print(f\"Using trial_period == {selected_trial_period} instead.\")\n",
    "        else:\n",
    "            raise ValueError(\"No trial periods available in trial_itt.expansion.\")\n",
    "    else:\n",
    "        selected_trial_period = 1\n",
    "    \n",
    "    newdata = trial_itt.expansion[trial_itt.expansion[\"trial_period\"] == selected_trial_period].copy()\n",
    "else:\n",
    "    raise KeyError(\"trial_period column not found in trial_itt.expansion.\")\n",
    "\n",
    "if 'trial_period_c' not in newdata.columns:\n",
    "    mean_trial_period = newdata[\"trial_period\"].mean()\n",
    "    newdata[\"trial_period_c\"] = newdata[\"trial_period\"] - mean_trial_period\n",
    "if 'followup_time_c' not in newdata.columns:\n",
    "    mean_followup_time = newdata[\"followup_time\"].mean()\n",
    "    newdata[\"followup_time_c\"] = newdata[\"followup_time\"] - mean_followup_time\n",
    "\n",
    "if 'cluster' in trial_itt.expansion.columns:\n",
    "    print(\"Number of rows before dropping NaN clusters:\", len(newdata))\n",
    "    newdata = newdata.dropna(subset=['cluster'])\n",
    "    print(\"Number of rows after dropping NaN clusters:\", len(newdata))\n",
    "\n",
    "if newdata.empty:\n",
    "    raise ValueError(\"newdata is empty after filtering. Check trial_period values or clustering.\")\n",
    "\n",
    "# Run prediction\n",
    "try:\n",
    "    preds = predict(trial_itt, newdata, predict_times=range(11))\n",
    "except Exception as e:\n",
    "    print(f\"Prediction failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Survival Difference Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(preds[\"difference\"][\"followup_time\"], preds[\"difference\"][\"survival_diff\"], 'k-', label=\"Survival Difference\")\n",
    "plt.plot(preds[\"difference\"][\"followup_time\"], preds[\"difference\"][\"2.5%\"], 'r--', label=\"95% CI Lower\")\n",
    "plt.plot(preds[\"difference\"][\"followup_time\"], preds[\"difference\"][\"97.5%\"], 'r--', label=\"95% CI Upper\")\n",
    "plt.xlabel(\"Follow up\")\n",
    "plt.ylabel(\"Survival difference\")\n",
    "plt.ylim(-0.15, 0.00)\n",
    "plt.xlim(0, 10)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title(\"Survival Difference Over Follow-up\")\n",
    "\n",
    "# Cluster Visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(trial_itt.expansion[\"age\"], trial_itt.expansion[\"x2\"], c=trial_itt.expansion[\"cluster\"], cmap='viridis')\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Patient Clusters Based on Age and x2\")\n",
    "plt.colorbar(scatter, label=\"Cluster\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate and print cluster insights\n",
    "cluster_summary = trial_itt.expansion.groupby('cluster').agg({\n",
    "    'outcome': 'mean',\n",
    "    'assigned_treatment': 'mean',\n",
    "    'age': 'mean',\n",
    "    'x2': 'mean',\n",
    "    'censored': 'mean'\n",
    "}).reset_index()\n",
    "print(\"\\nCluster Analysis Summary:\")\n",
    "print(cluster_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
